{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Image Data Extraction\n","\n","__Goal:__ Download images to use for braces prediction via before/after photos from orthodontic websites."]},{"cell_type":"markdown","metadata":{},"source":["## 0 Set Up"]},{"cell_type":"markdown","metadata":{},"source":["### 0.1 Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":217,"status":"ok","timestamp":1667102137608,"user":{"displayName":"Noah Wolfenzon","userId":"04704736013910661680"},"user_tz":240},"id":"8G9hffYWHqm5"},"outputs":[],"source":["# import utility libraries\n","import os\n","import re\n","import shutil\n","import time\n","\n","# import environment variables\n","from dotenv import load_dotenv\n","from environments import environment as env\n","\n","# import scraping libraries\n","from bs4 import BeautifulSoup\n","import requests\n","\n","# import google colab\n","from google.colab import files"]},{"cell_type":"markdown","metadata":{"id":"3qXrQ8lxnbau"},"source":["### 0.2 Directories\n","\n","Create directories to store raw data in google colab"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":199,"status":"ok","timestamp":1667102137805,"user":{"displayName":"Noah Wolfenzon","userId":"04704736013910661680"},"user_tz":240},"id":"GguyINy-a2o4"},"outputs":[],"source":["!mkdir -p data/raw"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1667102138012,"user":{"displayName":"Noah Wolfenzon","userId":"04704736013910661680"},"user_tz":240},"id":"yT-hdiwabALP"},"outputs":[],"source":["RAW_DATA_DIRPATH = 'data/raw'"]},{"cell_type":"markdown","metadata":{},"source":["### 0.3 Custom Utilities"]},{"cell_type":"markdown","metadata":{},"source":["Creating a `ToothScraper` class to support image scraping (site urls are stored in environment.py)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from environment.environment import SCRAPE_URLS"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class ToothScraper:\n","  '''web scraper class to scrape (fetch and download) dental images'''\n","\n","  def __init__(self, site_url: str, dest_dir: str, imgs_selector: str = 'img', img_url_parser = lambda img: img['src']):\n","    self.site_url = site_url\n","    self.dest_dir = dest_dir\n","    self.imgs_selector = imgs_selector\n","    self.img_url_parser = img_url_parser\n","\n","  @staticmethod\n","  def download_image(url: str, fpath: str):\n","\n","    # download the image\n","    res = requests.get(url, stream = True)\n","\n","    # check if the download was successful\n","    if res.status_code == 200:\n","\n","      # save the image to the file path\n","      with open(fpath, 'wb') as f:\n","        shutil.copyfileobj(res.raw, f)\n","\n","      return 0\n","\n","    else:\n","      print(f'Unable to fetch image: {url}')\n","      return 1\n","\n","  def fetch_img_urls(self):\n","\n","    # fetch the main page\n","    self.page = requests.get(self.site_url)\n","\n","    # parse the page\n","    self.soup = BeautifulSoup(self.page.content, 'html.parser')\n","\n","    # select all images\n","    img_tags = self.soup.select(self.imgs_selector)\n","\n","    # extract the image urls and filter out empty urls\n","    self.img_urls = list(filter(None, [self.img_url_parser(img) for img in img_tags]))\n","\n","\n","  def download_images(self):\n","    for i, url in enumerate(self.img_urls):\n","\n","      file_split = os.path.splittext(url)\n","      if len(file_split) != 2:\n","        print(f'Unable to parse file ending: {url}')\n","        continue\n","\n","      file_ending = file_split[1]\n","\n","      img_rename = f'raw_{i}{file_ending}'\n","      img_dest = os.path.join(self.dest_dir, img_rename)\n","\n","      ret = self.download_image(url, img_dest)\n","      if not ret:\n","        print(f'Unable to download file: {url}')\n","        continue\n","\n","      # sleep to avoid getting blocked\n","      time.sleep(0.25)"]},{"cell_type":"markdown","metadata":{},"source":["## 1 Scrape Data"]},{"cell_type":"markdown","metadata":{},"source":["### 1.1 Scrape the data from first URL (doing this 1-by-1 on the first pass)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# grab the first URL from the environments variable\n","url_1_obj = SCRAPE_URLS[0]\n","\n","# initialize the destination to save the images from first downlod\n","# TODO: automatically generate destination path\n","dest = os.path.join(RAW_DATA_DIRPATH, '1')"]},{"cell_type":"markdown","metadata":{},"source":["Define the site-specific `img_url_parser` (Note: many of the sites have varying conventions for where they're storing images and how they're reference in html)\n","\n","Initialize the `tooth_scraper` for the first URL"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# define the img_url parser for first url\n","def img_url_parser(img_tag):\n","\n","    img_url_re = re.compile(r'src=\\\"([a-zA-Z/0-9_\\-\\.]+)\\\"')\n","    re_search = img_url_re.search(str(img_tag))\n","    storage_url = url_1_obj['storage_url']\n","\n","    if re_search:\n","      return storage_url + re_search.groups(0)\n","\n","    return None\n","\n","# create the tooth scraper for first URL\n","tooth_scraper = ToothScraper(url_1_obj['site_url'], dest, imgs_selector='li img', img_url_parser=img_url_parser)"]},{"cell_type":"markdown","metadata":{},"source":["Scrape the web page to get the storage URLs of each image\n","\n","Download each image from the storage URL location"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# scrape the webpage for the image storage locations\n","tooth_scraper.fetch_img_urls()\n","\n","# download the images to google colab\n","tooth_scraper.download_images()"]},{"cell_type":"markdown","metadata":{"id":"BuDrvRy9nvS2"},"source":["Zip and save the data to google colab"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1405,"status":"ok","timestamp":1666995046323,"user":{"displayName":"Noah Wolfenzon","userId":"04704736013910661680"},"user_tz":240},"id":"TWf6FxfEeYh7","outputId":"62241cf2-80dd-4be7-ac28-25ff53bb8567"},"outputs":[],"source":["!zip -r data/1/raw.zip data/1/raw"]},{"cell_type":"markdown","metadata":{},"source":["### 1.2 Scrape data from the second URL"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ie5G5xbJpcFG"},"outputs":[],"source":["# grab the second URL from the environments variable\n","url_2_obj = SCRAPE_URLS[1]\n","\n","# initialize the destination to save the images from second downlod\n","# TODO: automatically generate destination path\n","dest = os.path.join(RAW_DATA_DIRPATH, '2')\n","\n","# define the img_url parser for second url\n","def img_url_parser(img):\n","\n","    img_url_re = re.compile(r'href=\\\"([a-zA-Z/0-9_\\-\\.]+)\\\" title')\n","    re_search = img_url_re.search(str(img))\n","    storage_url = url_2_obj['storage_url']\n","\n","    if re_search:\n","      return storage_url + re_search.groups(0)\n","\n","    return None\n","\n","# create the tooth scraper for second URL\n","tooth_scraper = ToothScraper(url_2_obj, dest, imgs_selector='div#links a', img_url_parser=img_url_parser)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# scrape the webpage for the image storage locations\n","tooth_scraper.fetch_img_urls()\n","\n","# download the images to google colab\n","tooth_scraper.download_images()"]},{"cell_type":"markdown","metadata":{},"source":["Zip and save the data to google colab"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!zip -r data/2/raw.zip data/2/raw"]},{"cell_type":"markdown","metadata":{},"source":["## 2 Save Locally"]},{"cell_type":"markdown","metadata":{},"source":["### 2.1 Download zipped files\n","\n","in the Google Colab UI, download the zipped data filed for subsequent training"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOmFhcsQ6QSOWzisHnYJc++","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"}},"nbformat":4,"nbformat_minor":0}
